{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1eeeca13-5593-4c12-801b-45e6dde88c01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting delta-spark==3.1.0\n",
      "  Downloading delta_spark-3.1.0-py3-none-any.whl.metadata (1.9 kB)\n",
      "Requirement already satisfied: pyspark<3.6.0,>=3.5.0 in /usr/local/spark/python (from delta-spark==3.1.0) (3.5.0)\n",
      "Requirement already satisfied: importlib-metadata>=1.0.0 in /opt/conda/lib/python3.11/site-packages (from delta-spark==3.1.0) (6.8.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.11/site-packages (from importlib-metadata>=1.0.0->delta-spark==3.1.0) (3.17.0)\n",
      "Collecting py4j==0.10.9.7 (from pyspark<3.6.0,>=3.5.0->delta-spark==3.1.0)\n",
      "  Downloading py4j-0.10.9.7-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Downloading delta_spark-3.1.0-py3-none-any.whl (21 kB)\n",
      "Downloading py4j-0.10.9.7-py2.py3-none-any.whl (200 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.5/200.5 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: py4j, delta-spark\n",
      "Successfully installed delta-spark-3.1.0 py4j-0.10.9.7\n"
     ]
    }
   ],
   "source": [
    "!pip install delta-spark==3.1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0dee80f1-03e7-4352-b9c6-a46fd1e65166",
   "metadata": {},
   "outputs": [],
   "source": [
    "from delta import *\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "\n",
    "builder = pyspark.sql.SparkSession.builder.appName(\"MyApp\") \\\n",
    "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n",
    "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\")\n",
    "\n",
    "spark = configure_spark_with_delta_pip(builder).getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a7c99cbe-7b77-4153-812d-b1f964f32fbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-----------------+\n",
      "|       originationId|count(originationId)|            table|\n",
      "+--------------------+--------------------+-----------------+\n",
      "|1b7d38015747cf95f...|                   2|fact_originations|\n",
      "|0aa4ed0bd95f5c014...|                   2|    fact_payments|\n",
      "+--------------------+--------------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#check if any duplicate records\n",
    "df = spark.sql(\"\"\"\n",
    "  SELECT originationId, \n",
    "      count(originationId) noOfDuplicates, \n",
    "      'fact_originations' table\n",
    "  FROM delta.`/data/delta/fact_originations/` fo\n",
    "  GROUP BY originationId\n",
    "  HAVING COUNT(originationId) > 1\n",
    "  UNION ALL\n",
    "  SELECT paymentId, \n",
    "      count(paymentId) noOfDuplicates, \n",
    "      'fact_payments' table\n",
    "  FROM delta.`/data/delta/fact_payments/`\n",
    "  GROUP BY paymentId\n",
    "  HAVING COUNT(paymentId) > 1\n",
    "\"\"\")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "41ad0e57-46ab-4e2a-a751-514c06e9e02e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------+------------+-----+----------------+\n",
      "|originationId|clientId|registerDate|value|installmentValue|\n",
      "+-------------+--------+------------+-----+----------------+\n",
      "+-------------+--------+------------+-----+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#check if all originations have installments\n",
    "df = spark.sql(\"\"\"\n",
    "  SELECT fo.originationId, fo.clientId, fo.registerDate, fo.value, fi.installmentValue\n",
    "  FROM delta.`/data/delta/fact_originations/` fo\n",
    "  LEFT JOIN delta.`/data/delta/fact_installments/` fi\n",
    "  ON fo.originationId = fi.originationId\n",
    "  WHERE fi.installmentValue IS NULL\n",
    "\"\"\")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1844928c-4018-45be-8cf2-ba2d3f02be59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+------------+------------+----------------+\n",
      "|       originationId|            clientId|registerDate|       value|installmentValue|\n",
      "+--------------------+--------------------+------------+------------+----------------+\n",
      "|1b7d38015747cf95f...|c67d5489eff1b9adf...|  2021-06-27|149.97000000|    299.94000000|\n",
      "|1b7d38015747cf95f...|                  55|  2021-06-27|149.97000000|    299.94000000|\n",
      "+--------------------+--------------------+------------+------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#check if all origination amount and total installment amount match\n",
    "df = spark.sql(\"\"\"\n",
    "  SELECT fo.originationId, fo.clientId, fo.registerDate, fo.value, SUM(fi.installmentValue) installmentValue\n",
    "  FROM delta.`/data/delta/fact_originations/` fo\n",
    "  LEFT JOIN delta.`/data/delta/fact_installments/` fi\n",
    "  ON fo.originationId = fi.originationId\n",
    "  GROUP BY fo.originationId, fo.clientId, fo.registerDate, fo.value\n",
    "  HAVING fo.value != SUM(fi.installmentValue)\n",
    "\"\"\")\n",
    "df.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
